{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공동주택 코드 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리\n",
    "import os\n",
    "import chardet\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "p = re.compile('\\(([^)]+)')  \n",
    "\n",
    "def jibun_juso(addr):\n",
    "    d = p.findall(addr) \n",
    "    if isinstance(d, list) and len(d) > 0:\n",
    "        return d[0]\n",
    "    return None\n",
    "\n",
    "def doro_juso(addr):\n",
    "    p = addr.find(\"(\")\n",
    "    juso = addr[0:p-1].rstrip()\n",
    "    return juso\n",
    "\n",
    "def part_back(obj):\n",
    "    # 데이터에 null 있음    \n",
    "    if isinstance(obj, str) and len(obj) > 0:\n",
    "        part_front = obj.split()[0]\n",
    "        part_back = obj.replace(part_front, \"\").lstrip()\n",
    "        return part_back\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def part_front(obj):\n",
    "    part_front = obj[1].replace(obj[0], \"\").rstrip()\n",
    "    return part_front\n",
    "\n",
    "def no_blank(obj):\n",
    "    # 데이터에 null 있음    \n",
    "    if isinstance(obj, str) and len(obj) > 0:\n",
    "        re_str = obj.replace(\" \", \"\")\n",
    "        return re_str\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 파일 위치\n",
    "data_root = \"D:\\PythonProject\\data-gatherer\\molit_apt\\data\"\n",
    "# 아파트 코드 목록: 외부(국토교통부)\n",
    "file_ext = os.path.join(data_root, \"공동주택_국토부_apt_info_20240411.csv\")\n",
    "# 아파트 코드 목록: 내부(고객지원시스템)\n",
    "file_int = os.path.join(data_root, \"공동주택_고객지원시스템_20240415.csv\")\n",
    "\n",
    "# 파일의 인코딩 확인\n",
    "with open(file_ext, 'rb') as f:\n",
    "    rawdata = f.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    encoding_ext = result['encoding']\n",
    "    \n",
    "with open(file_int, 'rb') as f:\n",
    "    rawdata = f.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    encoding_int = result['encoding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 데이터 읽기\n",
    "data_int = pd.read_csv(file_int, encoding=encoding_int, dtype=object)\n",
    "df_int = data_int.copy()\n",
    "int_cnt = df_int.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 데이터 정리 \"\"\"\n",
    "# 1. 공동주택이 아닌 데이터 제외\n",
    "idx = df_int[df_int['용도'] != '공동주택'].index\n",
    "df_int.drop(idx, inplace=True)\n",
    "# 2. 필요한 항목만 남김\n",
    "df_int = df_int[['아파트명', '아파트코드', '우편번호', '주소']]\n",
    "# 3. 중복 데이터 없애기\n",
    "df_int.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=True)\n",
    "# 4. 시군구 항목 생성\n",
    "df_int['시군구'] = df_int['주소'].apply(lambda x: x.split()[0])\n",
    "# 5. 대구광역시 공급권역 데이터만 남기고 나머지(경북 지역) 데이터 삭제\n",
    "idx = df_int[~df_int['시군구'].isin(['중구', '동구', '서구', '남구', '북구', '수성구', '달서구', '달성군'])].index\n",
    "df_int.drop(idx, inplace=True)\n",
    "# 6. 지번주소 항목 분리 생성\n",
    "df_int['지번주소'] = df_int['주소'].apply(jibun_juso)\n",
    "df_int['지번주소_공백X'] = df_int['지번주소'].apply(no_blank)\n",
    "# 7. 도로명주소 항목 분리 생성\n",
    "df_int['시군구_도로명주소'] = df_int['주소'].apply(doro_juso)\n",
    "df_int['도로명주소'] = df_int['시군구_도로명주소'].apply(part_back)\n",
    "df_int['도로명주소_공백X'] = df_int['도로명주소'].apply(no_blank)\n",
    "# 8. 아파트명 공백X\n",
    "df_int['아파트명_공백X'] = df_int['아파트명'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "# 9. 필요항 컬럼만 구성\n",
    "df_int = df_int[['아파트코드','아파트명', '아파트명_공백X', '시군구', '지번주소', '지번주소_공백X', '도로명주소', '도로명주소_공백X']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 데이터 읽기\n",
    "data_ext = pd.read_csv(file_ext, encoding=encoding_ext, dtype=object)\n",
    "df_ext = data_ext.copy()\n",
    "ext_cnt = df_ext.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ext.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 데이터 정리 \"\"\"\n",
    "# 1. 필요한 항목만 남김\n",
    "df_ext = df_ext[['kapt_cd', 'kapt_nm', 'as2', 'as3', 'as4', 'kapt_addr', 'doro_juso']]\n",
    "# 2. 시군구_도로명주소 항목 생성\n",
    "df_ext['시군구_도로명주소'] = df_ext['doro_juso'].str.lstrip('대구광역시')\n",
    "# 3. 도로명주소 항목 생성\n",
    "df_ext['도로명주소'] = df_ext['시군구_도로명주소'].apply(part_back)\n",
    "df_ext['도로명주소_공백X'] = df_ext['도로명주소'].apply(no_blank)\n",
    "# 4. 법정동주소 항목 생성   \n",
    "df_ext['광역시_법정동주소'] = df_ext[['kapt_nm', 'kapt_addr']].apply(part_front, axis=1)\n",
    "df_ext['시군구_법정동주소'] = df_ext['광역시_법정동주소'].apply(part_back)\n",
    "df_ext['법정동주소'] = df_ext['시군구_법정동주소'].apply(part_back)\n",
    "df_ext['법정동주소_공백X'] = df_ext['법정동주소'].apply(no_blank)\n",
    "# 5. 컬럼명 변경\n",
    "df_ext.rename(columns={'kapt_nm' : '아파트명', 'as2' : '시군구'}, inplace=True)\n",
    "# 6. 아파트명 공백X\n",
    "df_ext['아파트명_공백X'] = df_ext['아파트명'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "# 7. 필요한 컬럼만 구성\n",
    "df_ext = df_ext[['kapt_cd', '아파트명', '아파트명_공백X', '시군구', 'as3', 'as4', '도로명주소', '도로명주소_공백X', '법정동주소', '법정동주소_공백X']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1차 매칭 - 도로명주소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차 매칭\n",
    "df_merge1 = pd.merge(df_ext, df_int, how='outer', left_on=\"도로명주소_공백X\", right_on=\"도로명주소_공백X\", suffixes=('_left','_right'), indicator=True)\n",
    "df_match1 = df_merge1[df_merge1['_merge'] == 'both'][['kapt_cd', '아파트코드']]\n",
    "df_a = df_match1[df_match1.duplicated(subset='kapt_cd', keep=False)]       # N:1 Data\n",
    "df_b = df_match1[df_match1.duplicated(subset='아파트코드', keep=False)]     # 1:N Data\n",
    "df_dup = pd.concat([df_a, df_b])\n",
    "idx_dup = df_match1[df_match1.index.isin(df_dup.index)].index\n",
    "df_match1.drop(idx_dup, inplace=True)       # 데이터 삭제 (abnormal matching)\n",
    "df_match1['match'] = '1. 도로명주소 일치'\n",
    "# 1차 매칭된 데이터 삭제\n",
    "idx_ext = df_ext[df_ext['kapt_cd'].isin(df_match1['kapt_cd'])].index\n",
    "df_ext.drop(idx_ext, inplace=True)\n",
    "idx_int = df_int[df_int['아파트코드'].isin(df_match1['아파트코드'])].index\n",
    "df_int.drop(idx_int, inplace=True)\n",
    "assert df_ext.shape[0] == ext_cnt - df_match1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2차 매칭 - 아파트명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차 매칭\n",
    "df_merge2 = pd.merge(df_ext, df_int, how='outer', left_on=\"아파트명_공백X\", right_on=\"아파트명_공백X\", suffixes=('_left','_right'), indicator=True)\n",
    "df_match2 = df_merge2[df_merge2['_merge'] == 'both'][['kapt_cd', '아파트코드']]\n",
    "df_a = df_match2[df_match2.duplicated(subset='kapt_cd', keep=False)]       # N:1 Data\n",
    "df_b = df_match2[df_match2.duplicated(subset='아파트코드', keep=False)]     # 1:N Data\n",
    "df_dup = pd.concat([df_a, df_b])\n",
    "idx_dup = df_match2[df_match2.index.isin(df_dup.index)].index\n",
    "df_match2.drop(idx_dup, inplace=True)       # 데이터 삭제 (abnormal matching)\n",
    "df_match2['match'] = '2. 아파트명 일치'\n",
    "# 2차 매칭된 데이터 삭제\n",
    "idx_ext = df_ext[df_ext['kapt_cd'].isin(df_match2['kapt_cd'])].index\n",
    "df_ext.drop(idx_ext, inplace=True)\n",
    "idx_int = df_int[df_int['아파트코드'].isin(df_match2['아파트코드'])].index\n",
    "df_int.drop(idx_int, inplace=True)\n",
    "assert df_ext.shape[0] == ext_cnt - df_match1.shape[0] - df_match2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3차 매칭 - [EXT]법정동주소 == [INT]지번주소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3차 매칭\n",
    "df_merge3 = pd.merge(df_ext, df_int, how='outer', left_on=\"법정동주소_공백X\", right_on=\"지번주소_공백X\", suffixes=('_left','_right'), indicator=True)\n",
    "df_match3 = df_merge3[df_merge3['_merge'] == 'both'][['kapt_cd', '아파트코드']]\n",
    "df_a = df_match3[df_match3.duplicated(subset='kapt_cd', keep=False)]       # N:1 Data\n",
    "df_b = df_match3[df_match3.duplicated(subset='아파트코드', keep=False)]     # 1:N Data\n",
    "df_dup = pd.concat([df_a, df_b])\n",
    "idx_dup = df_match3[df_match3.index.isin(df_dup.index)].index\n",
    "df_match3.drop(idx_dup, inplace=True)       # 데이터 삭제 (abnormal matching)\n",
    "df_match3['match'] = '3. 국토부_법정동주소와 내부시스템_지번주소 일치'\n",
    "# 3차 매칭된 데이터 삭제\n",
    "idx_ext = df_ext[df_ext['kapt_cd'].isin(df_match3['kapt_cd'])].index\n",
    "df_ext.drop(idx_ext, inplace=True)\n",
    "idx_int = df_int[df_int['아파트코드'].isin(df_match3['아파트코드'])].index\n",
    "df_int.drop(idx_int, inplace=True)\n",
    "assert df_ext.shape[0] == ext_cnt - df_match1.shape[0] - df_match2.shape[0] - df_match3.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4차 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4차 매칭\n",
    "df_ext['as3_도로명주소_공백X'] = df_ext['as3'] + df_ext['도로명주소_공백X']\n",
    "df_merge4 = pd.merge(df_ext, df_int, how='outer', left_on=\"as3_도로명주소_공백X\", right_on=\"도로명주소_공백X\", suffixes=('_left','_right'), indicator=True)\n",
    "df_match4 = df_merge4[df_merge4['_merge'] == 'both'][['kapt_cd', '아파트코드']]\n",
    "df_a = df_match4[df_match4.duplicated(subset='kapt_cd', keep=False)]       # N:1 Data\n",
    "df_b = df_match4[df_match4.duplicated(subset='아파트코드', keep=False)]     # 1:N Data\n",
    "df_dup = pd.concat([df_a, df_b])\n",
    "idx_dup = df_match4[df_match4.index.isin(df_dup.index)].index\n",
    "df_match4.drop(idx_dup, inplace=True)       # 데이터 삭제 (abnormal matching)\n",
    "df_match4['match'] = '4. 국토부_읍면+도로명주소와 내부시스템_도로명주소 일치'\n",
    "# 4차 매칭된 데이터 삭제\n",
    "idx_ext = df_ext[df_ext['kapt_cd'].isin(df_match4['kapt_cd'])].index\n",
    "df_ext.drop(idx_ext, inplace=True)\n",
    "idx_int = df_int[df_int['아파트코드'].isin(df_match4['아파트코드'])].index\n",
    "df_int.drop(idx_int, inplace=True)\n",
    "assert df_ext.shape[0] == ext_cnt - df_match1.shape[0] - df_match2.shape[0] - df_match3.shape[0] - df_match4.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5차 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_char = {\"LH\" : \"엘에이치\", \"e\" : \"이\"}\n",
    "def re_char(apt_name):\n",
    "    y = apt_name\n",
    "    for k, v in same_char.items():\n",
    "        if k in apt_name:\n",
    "            y = apt_name.replace(k, v)\n",
    "    return y\n",
    "\n",
    "# 5차 매칭\n",
    "df_ext['아파트명_공백X_단어통일'] = df_ext['아파트명_공백X'].apply(re_char)\n",
    "df_int['아파트명_공백X_단어통일'] = df_int['아파트명_공백X'].apply(re_char)\n",
    "df_merge5 = pd.merge(df_ext, df_int, how='outer', left_on=\"아파트명_공백X_단어통일\", right_on=\"아파트명_공백X_단어통일\", suffixes=('_left','_right'), indicator=True)\n",
    "df_match5 = df_merge5[df_merge5['_merge'] == 'both'][['kapt_cd', '아파트코드']]\n",
    "df_a = df_match5[df_match5.duplicated(subset='kapt_cd', keep=False)]       # N:1 Data\n",
    "df_b = df_match5[df_match5.duplicated(subset='아파트코드', keep=False)]     # 1:N Data\n",
    "df_dup = pd.concat([df_a, df_b])\n",
    "idx_dup = df_match5[df_match5.index.isin(df_dup.index)].index\n",
    "df_match5.drop(idx_dup, inplace=True)       # 데이터 삭제 (abnormal matching)\n",
    "df_match5['match'] = '5. 아파트명 유사단어 통일 후 일치'\n",
    "# 5차 매칭된 데이터 삭제\n",
    "idx_ext = df_ext[df_ext['kapt_cd'].isin(df_match5['kapt_cd'])].index\n",
    "df_ext.drop(idx_ext, inplace=True)\n",
    "idx_int = df_int[df_int['아파트코드'].isin(df_match5['아파트코드'])].index\n",
    "df_int.drop(idx_int, inplace=True)   \n",
    "assert df_ext.shape[0] == ext_cnt - df_match1.shape[0] - df_match2.shape[0] - df_match3.shape[0] - df_match4.shape[0] - df_match5.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 6차 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_char = ['대구', '아파트']\n",
    "def del_char(apt_name):\n",
    "    y = apt_name\n",
    "    for c in extra_char:\n",
    "        if c in y:\n",
    "            y = y.replace(c, \"\")     # 해당 단어 삭제\n",
    "    return y\n",
    "\n",
    "# 6차 매칭\n",
    "df_ext['아파트명_공백X_부가단어삭제'] = df_ext['아파트명_공백X'].apply(del_char)\n",
    "df_int['아파트명_공백X_부가단어삭제'] = df_int['아파트명_공백X'].apply(del_char)\n",
    "df_merge6 = pd.merge(df_ext, df_int, how='outer', left_on=\"아파트명_공백X_부가단어삭제\", right_on=\"아파트명_공백X_부가단어삭제\", suffixes=('_left','_right'), indicator=True)\n",
    "df_match6 = df_merge6[df_merge6['_merge'] == 'both'][['kapt_cd', '아파트코드']]\n",
    "df_a = df_match6[df_match6.duplicated(subset='kapt_cd', keep=False)]       # N:1 Data\n",
    "df_b = df_match6[df_match6.duplicated(subset='아파트코드', keep=False)]     # 1:N Data\n",
    "df_dup = pd.concat([df_a, df_b])\n",
    "idx_dup = df_match6[df_match6.index.isin(df_dup.index)].index\n",
    "df_match6.drop(idx_dup, inplace=True)       # 데이터 삭제 (abnormal matching)\n",
    "df_match6['match'] = '6. 아파트명 부가단어 삭제 후 일치'\n",
    "# 6차 매칭된 데이터 삭제\n",
    "idx_ext = df_ext[df_ext['kapt_cd'].isin(df_match6['kapt_cd'])].index\n",
    "df_ext.drop(idx_ext, inplace=True)\n",
    "idx_int = df_int[df_int['아파트코드'].isin(df_match6['아파트코드'])].index\n",
    "df_int.drop(idx_int, inplace=True)   \n",
    "assert df_ext.shape[0] == ext_cnt - df_match1.shape[0] - df_match2.shape[0] - df_match3.shape[0] - df_match4.shape[0] - df_match5.shape[0] - df_match6.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 총합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대구광역시 국토부 데이터:\t 1039\n",
      "고객지원시스템 데이터:\t 3170\n",
      "매칭: 1차 매칭 831, 2차 매칭 106, 3차 매칭 29, 4차 매칭 43, 5차 매칭 4, 6차 매칭 6\n",
      "총 매칭 1019, 잔여 건수(국토부 데이터 기준) 20\n"
     ]
    }
   ],
   "source": [
    "m1 = df_match1.shape[0]\n",
    "m2 = df_match2.shape[0]\n",
    "m3 = df_match3.shape[0]\n",
    "m4 = df_match4.shape[0]\n",
    "m5 = df_match5.shape[0]\n",
    "m6 = df_match6.shape[0]\n",
    "total = m1 + m2 + m3 + m4 + m5 + m6\n",
    "print(f\"대구광역시 국토부 데이터:\\t {ext_cnt}\")\n",
    "print(f\"고객지원시스템 데이터:\\t {int_cnt}\")\n",
    "print(f\"매칭: 1차 매칭 {m1}, 2차 매칭 {m2}, 3차 매칭 {m3}, 4차 매칭 {m4}, 5차 매칭 {m5}, 6차 매칭 {m6}\")\n",
    "print(f\"총 매칭 {total}, 잔여 건수(국토부 데이터 기준) {ext_cnt - total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match\n",
       "1. 도로명주소 일치                        831\n",
       "2. 아파트명 일치                         106\n",
       "4. 국토부_읍면+도로명주소와 내부시스템_도로명주소 일치     43\n",
       "3. 국토부_법정동주소와 내부시스템_지번주소 일치         29\n",
       "6. 아파트명 부가단어 삭제 후 일치                 6\n",
       "5. 아파트명 유사단어 통일 후 일치                 4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 매칭 데이터 병합\n",
    "df_list = [df_match1, df_match2, df_match3, df_match4, df_match5, df_match6]\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "df_all.sort_values(by='match')['match'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 결과 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = df_all.copy()\n",
    "data_all = pd.merge(data_all, data_ext[['kapt_cd','kapt_nm']], how='left', left_on='kapt_cd', right_on='kapt_cd') \n",
    "data_all = pd.merge(data_all, data_int[['아파트코드','아파트명']], how='left', left_on='아파트코드', right_on='아파트코드') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "#1. 파일 생성\n",
    "file_matching = os.path.join(data_root, \"공동주택_매칭결과.xlsx\")\n",
    "writer = pd.ExcelWriter(file_matching, engine='xlsxwriter')\n",
    " \n",
    "with pd.ExcelWriter(file_matching) as writer:\n",
    "    data_all.to_excel(writer, sheet_name='Matched')\n",
    "    df_ext.to_excel(writer, sheet_name='Unmatched_국토부')\n",
    "    df_int.to_excel(writer, sheet_name='Unmatched_고객지원시스템')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-gatherer-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
